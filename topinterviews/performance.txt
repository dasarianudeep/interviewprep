SDI Concepts - 
----------------

AVAILABILITY - Availability is the percentage of time that some service  is accessible to clients and is operated upon
 under normal conditions.

RELIABILITY - R measures how the service performs under varying operating conditions.
 MTBF - total Uptime / Total Failures
 MTTR - Total maintenace time / Total Repairs

SCALABILITY is the ability of a system to handle an increasing amount of workload without compromising performance.

FAIULT TOLERANCE refers to a system’s ability to execute persistently even if one or more of its components fail

Monolith - Built and deployed as single unit 
Pros - 
1.)Easy development and Fast deployment.
2.)Simple and uncomplicated testing and montoring
3.)

Cons - 
1.)Tough and challenging to scale.
2.)Tight Coupling.
3.)System fragility - if one part of monolity fails, the entire monilith fails.
4.)Low agility - If maintaoned by multiple teams, relase, rollout, bug fixes and feat iterations are all to be 
coordinated.

Microservices - Build and deployed as collection of independent and isolated services.
Pros - Granular Scalability, Reusability, Reliability, Tech agnostic
Cons - Increased complexity, Difficult in Testing and debugging, Deployment overhead


How to design for Scale and HA -
--------------------------------
*No SPOF, Design a multi-zone architecture by distribuitng pool of services across mul zones with date replication,
load balancing and automated failover between zones.
*Replicate data across regions for DR i case of regional outage.
*Design mult-region architecture for resilience to regional outages.
*Enable Auto-scaling in VMs, DBs -  sharding.
*Degrade service levels gracefully when overloaded -  Services should detect overload and return lower quality 
responses to the user or partially drop traffic, not fail completely under overload.
*Prevent and mitigate traffic spikes - throttling, queueing, circuit breaking, graceful degradation, prioritizing critical requests.
*Fail safe - If there's a failure due to a problem, the system components should fail in a way that allows the 
overall system to continue to function
*Design API calls and operational commands to be retryable - Idempotent actions
*Minimize Cirtical Dependencies - increase redunancy, use asyn processing(queue, pubsub)
*Ensure that every change can be rolled back

*Common ways to ensure a system is highly available include:

Diverting traffic to other servers seamlessly without losing data by employing tools like load balancers, reverse proxies, and DNS
Investing in redundancy by leveraging database replication, regions, and availability zones
Protecting the system from failures and atypical behaviors by utilizing circuit breakers, rate limiting, load shedding, and retries
Detecting system failures with monitoring tools and techniques like chaos engineering

SQL vs NoSQL - 
----------------
SQL - Structured Data, Strict Schema, Relational Data, Need for complex joins, TXNS, Date Integrity, Vertical scaling
NoSQL - Schemaless, unstructured or semi-structured data, High QPS load, Denormalised.

Denormalization Benefits - Reduce the number of joins, Simpler and performant queries, REduces complexity

NoSQL databases are likely the better choice when:

You have a large volume and variety of data, data is semi or unstructured
Scalability is a top priority
You need continuous availability
Working with big data or performing real-time analytics

API Gateway vs LB 
-------------------
An API gateway is a layer that sits between the client and the backend services.
 It acts as a front door for your backend services, routing requests, and handling the various
  cross-cutting concerns such as security, authentication, rate limiting, and protocol translation.
   API gateways can also provide a unified API for different microservices and can aggregate responses 
   from multiple services

A load balancer is a device or software component that distributes network traffic across a group of backend servers. 
Load balancers can ensure that traffic is evenly distributed across the servers, which can help avoid overloading
 individual servers, leading to better performance and availability.

 CDNs -  Distributed group of servers that caches content near end users
 ------
 *Resource Delivery - 
 When a CDN is used to deliver resources from the origin, a new connection is established between the client and a
  nearby CDN server. The remainder of the journey (in other words, the data transfer between the CDN server and
   origin) occurs over the CDN's network - which often includes existing, persistent connections with the origin. 

*Some CDNs improve upon this even further by routing traffic to the origin through multiple CDN servers 
spread across the Internet. Connections between CDN servers occur over reliable and highly optimized routes, 
rather than routes determined by the Border Gateway Protocol (BGP).


*Features - Caching at edge servers, Brotli Compression, Image Optimization, 

Features / Advantages of message queues
*Decoupling: Operations of the consumer and producer are completely independent of one another.
*Scalability: The number of producers and consumers can easily be scaled as required.
Buffering and load management: Message queues act essentially as data buffers. In case of a spike in the amount of data that needs to be processed by the consumer service, the latter needs not be made aware of the fact. The message queue buffers the data for the service, and the service only needs to process the data one by one, rather than having to manage a large amount of data all at once. This makes your architecture more robust overall.
*Resiliency: Even if your consumer processes go down, it doesn't mean that your application breaks. Messages for the consumer will remain queued in the messaging queue. Whenever the consumer service comes back up, it can start processing the messages without having to do any additional setup or work.
*Delivery guarantees: Message queues offer a general guarantee that any message that gets pushed to a queue will get delivered to a consumer eventually.
*Order guarantee: Being a queue, an order is associated to the incoming messages implicitly. The same order is followed in the consumption and processing of the data.

Message Queue 
---------------
Queues can be great in scenarios where your application needs something ton be done but doesn’t need it be done right now,
 or doesn’t even care about the result. Instead of calling a web service and waiting for it to complete,
  you can write the message to a queue and let the same business logic happen later

*It provides a way to deliver messages to an application asynchronously, which means that it does not need to
 wait for a response before sending the next message.
*An asynchronous form of communication where one program or person sends a message to another program or person,
 but doesn't wait for an immediate response or acknowledgment.
*Better Decoupling
*Scalability
*Increased Reliability - In the event of a system crash, message queues also have the option to store the messages 
in their memory. The messages would be kept in the queue. For instance, if the client that was supposed to 
receive the message broke down for any reason. The message queues can play the message once the client's machine
 is up
*Traffic Spikes -  Message queues are effective at handling traffic spikes. Without message queues, it's
 possible that your system might have broken because of traffic spikes. This would result in the loss of the
  messages. The usage of a message queue, however, allows your server to process messages at its own pace and 
  eliminates the need to handle traffic surges on the server.How do you analyze Web application Performance
  *Batching is a great reason to use message queues.
  *

Dead-letter queues (DLQ) exist alongside regular message queues. They act as temporary storage for erroneous 
and failed messages. DLQs prevent the source queue from overflowing with unprocessed messages.

  GraphQL vs REST
  -----------------
1.)GraphQL APIs have a strongly typed schema
2.) Developers often describe the major benefit of GraphQL with the fact that clients can retrieve exactly the data
 they need from the API. They don’t have to rely on REST endpoints that return predefined and fixed responses.
 3.)RAPID Product Iteration - GraphQL exposes a single endpoint that allows you to access multiple resources.
 4.)GraphQL simplifies the task of aggregating data from multiple sources or APIs and then resolving the data 
 to the client in a single API call. On the other hand, API technologies like REST would require multiple HTTP 
 calls to access data from multiple sources
 5.) No Caching in GraphQL
 6.) Error handling in REST is easier when compared to GraphQL.
 7.) N+1 query problem-
 where a client application calls the server N+1 times to fetch one collection resource + N child resources

 gRPC vs REST
 ------------
 Client application can directly call a method on server application on different machine as if it were a local object,

*gRPC’s low-latency and high-speed throughput communication make it particularly useful for connecting 
architectures that consist of lightweight microservices where the efficiency of message transmission is paramount.

*Low-power, low-bandwidth networks: gRPC’s use of serialized Protobuf messages offers lightweight messaging,
 greater efficiency, and speed for bandwidth-constrained, low-power networks (especially when compared to JSON). 
 IoT would be an example

 *The protocol buffer is language agnostic, so you can make clients in Python and servers in Go and still be able to communicate without making any fuss.

 *Rest does not provide built-in code generation features, meaning the developer needs third-party apps to produce API 
 code, whereas gRPC has native code generation features due to its protobuf compiler, which is compatible with 
 several programming languages. 

 *gRPC enables you to manage bidirectional streaming to send and receive messages in real-time


Location Based applications -
------------------------------
*Geospatial data, or geodata, is data that includes information related to locations on the Earth’s surface. 
You can map objects, events, to a specific geographical area identified by latitude and longitude coordinates. 

*Geohash is a convenient way of expressing a location (anywhere in the world) using a short alphanumeric string, 
with greater precision obtained with longer strings.

*It works by reducing the two-dimensional longitude and latitude data into a one-dimensional string of letters and 
digits. Geohash algorithms work by recursively dividing the world into smaller and smaller grids

*The precision factor determines the size of the grid. We are only interested in geohashes with lengths between 4 and 6.


DB Locking -
--------------

https://convincedcoder.com/2018/09/01/Optimistic-pessimistic-locking-sql/#locking-strategies
Optimistic Locking is a strategy where you read a record, take note of a version number and check that the version 
hasn't changed before you write the record back. When you write the record back you filter the update on the version
 to make sure it's atomic. (i.e. hasn't been updated between when you check the version and write the record to
  the disk) and update the version in one hit.

  Pessimistic Locking is when you lock the record for your exclusive use until you have finished with it. 
  It has much better integrity than optimistic locking but requires you to be careful with your application 
  design to avoid Deadlocks. 

Consistency - 
---------------
*Eventual consistency offers low latency at the risk of returning stale data
*Strong Consistency offers up-to-date data but at the cost of high latency.

Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about 
themselves and about other nodes they know about.

REDIS sorted set is a collection of unique strings (members) ordered by an associated score. 

Consistent hashing facilitates the distribution of data across a set of nodes in such a way that minimizes the re-mapping/ reorganization of data when
 nodes are added/removed.


CRDTs-
------
Conflict-free replicated data types (CRDTs) allow replication of a
data structure across multiple machines without risking conflicts
between different versions. Even though each machine may concurrently modify its own copy of the data structure, 
a CRDT guarantees that these concurrent modifications can be merged into a
consistent result finally.
---------------------------------------------------------------------------------------------------------------

1.) Analyze Network Tab - 
Large assets - JS, images
Long running requests - manually defer code exec setTimeout(() => {}, 0), Web Workers, scheduler postTask,
 requestIdleCallback
postTask() allows for finer-grained scheduling of tasks, and is one way to help the 
browser prioritize work so that low priority tasks yield to the main thread
Identify large blocking resources, lazyload
Ensure assets are gzipped
Ensure no duplicate assets are downloaded.

2.) Analyze DOM Content - <=1500
 A large DOM can increase memory usage, cause longer style calculations, and produce costly layout reflows

 3.) Analyze Application Bundles
 webpack-bundle-analyzer
 
 CORE WEB VITALS (CWV) - Standard metrics from Google to measure UX of webpage. It measure different aspects of UX - 
 loading, interactivity and visual stability.
 Field (RUM) - data collected from real users visting the website - CRUX reports, PSI, GSC
 Lab - data collected in a controlled environment with predefined device and network settings - Lighthouse


CLS - Measures how much layout shifts unexpectedly when user lands on your page. (<=0.1)

Causes - 

*Images without dimensions: always include w and h attrs on image/video. or AR. Browser allocates correct space in
the document which loading.
*Ads/embeds/iframes without dimensions: website inserts ad containers dynamically/site resizes ad container
Statically reserve space for ad slot (min-height), placeholders and avoid collapsing space when no ad content is returned
*Dynamic Content: Avoid inserting new content above existing unless in response to user interaction.
If you want to display, reserve sufficent space in viewport in advance.
Replace the old content with new content in fixedsize container / load content offscreen  and show as overlay.
*Web Fonts causing FOIT/FOUT: <link rel="preload" ..../>, font-display: optional
if performance is priority: font-display: optional
If displaying text quickly is a top priority, but you want to still ensure the web-font is used: font-display: swap

LCP - Measures the time from when page starts loading to when large text block or image element is rendered.

1.)TTFB - The time from when the user starts initiating the load until browser receives 1st byte from HTML
2.)RLD - Time diff b/n TTFB and when browser starts loading LCP resource.
3.)RLT - Time it takes to load LCP resource
4.)ERD - Time diff between when LCP resource finishes loading until LCP element is rendered.

Resource Load Delay - 
Goal in this step is to ensure LCP resource starts loading asap.
    Optimise resource discovery - LCP element is <img> element in initial markup. If BG image, preload in HTML markup
If it is dynamically injected via JS(CSR/lazyloading), Preload the image with high priority
<link rel="preload" fetchpriority="high" as="image" href="/path/to/hero-image.webp" type="image/webp">
    Optimise resource priority - 
    <img fetchpriority="high" src="/path/to/hero-image.webp">

Resource Load Time -  reduce size, reduce distance the resource has to travel, eliminate network time entirely
    Reduce size - Serve responsive images
     The webpage shouldn't serve images that are larger than the version that's rendered on viewport.
    <img src="flower-large.jpg" srcset="flower-small.jpg 480w, flower-large.jpg 1080w" sizes="50vw">
                - Serve modern next-gen formats - .webp, .avif
                - Compress images
    Reduce distance - CDNs, image CDNs which also reduce size simultaneously
    Eliminate Network Time - data URL; longer delays due to decode cost

 Element Render Delay - 
 Goal in this step is to render immediately LCP element as soon as it finishes loading.
    Reduce or  inline RB Stylesheets - inline styles or reduce stylesheet size (remove unused CSS, defer non-critical css)
    <link rel="preload" href="styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    Defer or inline scripts - Dont add scripts without async, defer attr in head section
    Reduce JS size - analyse bundles and remove unused modules, replace heavy libraries with light weight alternatives
                    defer JS loading via code splitting on demand


Reduce TTFB - <800ms
    Optimise server processing times, DB queries, avoid multiple page redirects, use CDN to cut response time.

    CDNs - Brotli compression, TLS 1.3 (33% vs 1.2), HTTP/2(multiplexing, header compression), HTTP/3 (HOL blocking, 1.3)
            Minification, Image Optimization



LOAD 3RD PARTY SCRIPTS - 

*Use async,defer attributes on script tags
*Establish early connections - dns-prefetch, preconnect
*Lazy load embedded videos,media
*Avoid scripts that pollute the global scope
*Use CDNs
*Sub resource integrity 
    Subresource Integrity (SRI) is a security feature that enables browsers to verify that resources they
     fetch (for example, from a CDN) are delivered without unexpected manipulation. 
     It works by allowing you to provide a cryptographic hash that a fetched resource must match.

For embedded media -
*Only HTTPS
*Consider sandbox attr on iframe
*CSP

LOAD FONTS - 

*Preconnect to 3rd party origins.
*Use modern WOFF2 format
*font-display: optional
    Informs the browser how it should proceed with text rendering when the associated web font has not loaded.

CRITICAL RENDERING PATH -
Bytes => Characters => Tokens => Nodes => DOM/CSSOM construction
RenderTree - used to compute the layout of each visible element and serves as an input to the paint process that 
            renders the pixels to screen. 



*Adaptive Loading on mobile - connection aware 
*Offline - SW 



----------------------------NEWSFEED-----------------------------------

Fanout on write. With this approach, news feed is pre-computed during write time. 
A new post is delivered to friends’ cache immediately after it is published.

Pros:

The news feed is generated in real-time and can be pushed to friends immediately.

Fetching news feed is fast because the news feed is pre-computed during write time.

Cons:

If a user has many friends, fetching the friend list and generating news feeds for all of them are
 slow and time consuming. It is called hotkey problem.

For inactive users or those rarely log in, pre-computing news feeds waste computing resources.

Fanout on read. The news feed is generated during read time. This is an on-demand model. 
Recent posts are pulled when a user loads her home page.

Pros:

For inactive users or those who rarely log in, fanout on read works better because it will not waste computing resources on them.

Data is not pushed to friends so there is no hotkey problem.

Cons:

Fetching the news feed is slow as the news feed is not pre-computed.


We adopt a hybrid approach to get benefits of both approaches and avoid pitfalls in them.
 Since fetching the news feed fast is crucial, we use a push model for the majority of users.
  For celebrities or users who have many friends/followers, we let followers pull news content on-demand to 
  avoid system overload. 

  ------------------------------------------------------------------------------------------------------------
  IS vs Pagination - 
  IS is best suited when used jus wants to explore with large amount on UGC.
  Pagination is suiteable for goal-oriented apps when the user searches for a specific piece of content.

  IS Pros - User Engagement (reduces bounce rate), Scroll is better than click, offers good UX for  Mobile 
  IS Cons - Performance, SEO, Item search and location, browse endlessely not knowing the end of the content,same
            scrollbar is deceptive, no footer, relatively hard to implement IS than pagination
Pagination Pros - Good conversion, Sense of control, Item Location
Pagination Cons - Extra actions

-----------------------------------------------------------------------------------------------------------------
GraphQL vs REST
1.)GraphQL APIs have a strongly typed schema
2.) Developers often describe the major benefit of GraphQL with the fact that clients can retrieve exactly the data
 they need from the API. They don’t have to rely on REST endpoints that return predefined and fixed responses.
 3.)RAPID Product Iteration - GraphQL exposes a single endpoint that allows you to access multiple resources.
 4.)GraphQL simplifies the task of aggregating data from multiple sources or APIs and then resolving the data 
 to the client in a single API call. On the other hand, API technologies like REST would require multiple HTTP 
 calls to access data from multiple sources
 5.) No Caching in GraphQL
 6.) Error handling in REST is easier when compared to GraphQL.
 7.) N+1 query problem-
 where a client application calls the server N+1 times to fetch one collection resource + N child resources

 ------------------------------------------------ CACHING STRATEGIES ---------------------------------------------
 CACHE-ASIDE: Read Heavy workloads
 Pros -
 *Systems using cache-aside strategy are resilient to cache failures.
 Cons - 
 *Ensuring data consistency is challenging due to the lack of atomic operations on cache and storage.
 *Always a cache miss for the first time and increased latency.

 READ-THROUGH: Read Heavy workloads
 Pros -
 *The application only needs to read from the cache, simplifying the application code.
 Cons - 
 *The system cannot tolerate cache failures, as the cache plays a crucial role in the data retrieval process.
 *The cache and storage systems must share the same data model, limiting the flexibility in handling diff use cases.

 Similar to cache-aside, data consistency can pose challenges in a read-through strategy. 
 If the data in the storage is updated after being cached, inconsistencies may arise.

 WRITE-THROUGH: Write Heavy
 In this write strategy, data is first written to the cache and The cache updates the data in the main database
 Pros -Data is always available in cache and wont result in 'cache miss'.
Cons - Increased write latency.

WRITE-AROUND: 
The application writes data directly to storage system and then 1.)write k,v to cache 2.)invalidate cache 3.)Do ntng (ttl)

WRITE-BACK: Write Heavy
similar to write-through,with the primary diff being that write operations to the storage system are asynchronous.

Pros - Reduced write latency than write-through
Cons - Data inconsistency between cache and database.
If the cache fails before writing data to the storage, the latest updated records may be lost, 
which is not acceptable in some scenarios. To mitigate the risk of data loss due to cache failures,
 cache systems can persist write operations on the cache side. When the cache restarts, 
 it can replay the unfinished operations to recover the cache and write data to the storage system. 

 Cache busting - Specify diff versions of file, fingerprinting or adding query parameters


 Sync vs Async Communication - 
 -----------------------------
 Sync - Low performance,  Tight coupling, Hard to scale when u have high traffic,
 Async - Loosely coupled, Resilient - Decoupled services work independently and failure in one doesn’t cause a
  failure in another. The client of the service won’t be immediately affected. This makes it easier to 
  achieve high-availability of mission-critical systems.

 REST API Design Guidelines -
 ------------------------------ 
 Designing the Spec - how API structure should look like?
 Define endponts, available operations,outling input parameters and output parameters, describing auth methods
 Postman collections
 Documentation

 Versioning - Only when u have a backward-incompatible platform change, API is no more extendable,out-of-date spec
 Swagger - intuitive API Designer, API Console, API Documentation, Mocking Service
 intuitive way to visually design your APIs

 URI versioning, Query parameter, Custom header - Accept-version:v1, Accept header
 Accept: application/vnd.example.v1+json

 API authentication -
 *API key - Simple to implement, identification only, long-lived
 *Oauth2 - Authorization grant flow, client-credentials flow (no user authentication)
 *SAML - open standard for exchanging auth and authorization between IDP and SP.


Desigining the resources - 

 URL's should be nouns, Content-Types

Caching - Cache-Control Header

HTTP Response Code - 1xx - Informational, 2xx - Successful, 3xx - Redirection, 4xx - Client, 5xx - Service

HTTP Error Handling - 
{	
"error":	{	
"code":	400,	
"message":	"The	user	was	missing	required	fields",
"errors":	[{	
"domain":	"global",	
"reason":	"MissingParameter",	
"message":	"User	first	name	cannot	be	empty",	
"locationType":	"parameter",	
"location":	"firstName",	
"extendedHelp":	
"http://docs.domain.ext/users/post"	
},


Securing APIs -  SQL Injection, XSS, DDOS, MITM
Auth
Throttling and rate limiting allow you to prevent abuse of your API, and
ensure that your API withstands large numbers of calls
Validating and Sanitising input parameters
Log request and response activity, Conducting Pen Testing
Practice the principle of least privilege, Encrypt traffic using TLS
Tokenization

CORS
IP Whitelisting
JSON Threat protection - policy to validate a JSON request body by specifying limits for various JSON structures
maxEntries, maxArraySize, maxDepth, maxNameLength, maxValueLength


Analytics - 


---------------------------------------WEB SECURITY---------------------------------------------------------------
CORS - 

SOP blocks reading a resource from a different origin.SOP tells the browser to block cross-origin requests.
1.) Browser => Service "Origin" header
2.) Service => Browser "Access-Control-Allow-Origin" header
Share Credentials in CORS
fetch(url, {mode: 'cors', credentials: 'include'});
Access-Control-Allow-Origin must be set to a specific origin (no *) and must set Access-Control-Allow-Credentials to true.

The CORS specification defines a complex request as

*A request that uses methods other than GET, POST, or HEAD
*A request that includes headers other than Accept, Accept-Language or Content-Language
*A request that has a Content-Type header other than application/x-www-form-urlencoded, multipart/form-data, or text/plain

Server response can also include an "Access-Control-Max-Age" header to specify the duration to cache preflight results 

CSRF - 

CSRF Mitigation -
*Accepting only JSON Content-Type - no way for a simple <form> to send JSON
*Disable CORS - Only allow OPTIONS, GET, HEAD
*Check the referrer header
*GET should not have side effects
*CSRF Tokens
-------------------------------------------------------------------------------------------------------------------


Web Sockets vs SSE vs Long-Polling
------------------------------------

WS - allows bi-directional communication between cliet and server. Transmit both binary and text data.
Pros - Reduced resource utilization since persistent connection is established.

Cons - WS do not automatically recover when connections are terminated. 
Some firewalls block WS connections.
Require good upfront work to enable.
No HTTP headers from Server are passed; reduced data payload
You can't leverage caching like HTTP - Intermediate/Edge caching

SSE - Mono-directional(server-to-client) and transported over simple HTTP protocol. Builtin support for reconnection
Event IDs
No firewall issues
Ideal for  live-stocks base apps, Subs to Twitter feed, Receiving live sports score, News update and alternatives

Cons - SSE suffers from a limitation to the maximum  of 6 open connections, which can be especially
 painful when opening multiple tabs, as the limit is per browser and is set to a very low number 
 Lacks extensiblity
 Does not support binary data.


 Long Polling - 
 In long polling, a client holds the connection open until there are actually new messages available or a 
 timeout threshold has been reached. Once the client receives new messages, it immediately sends another request to the server,
  restarting the process
Pros - Simple to implement,based on HTTP. It works in every browser and environment.
Cons - Higher latency, Resource intensive Creates new connection each time, which can be intensive on the server.


MOBILE OPTIMIZATIONS - 

*Your site should have big and easy clickable buttons. 
*Responsive web design
*Compress images
*People use mobile devices of diff screen sizes. When designing a user interface, customize it for diff screen resolutions 
using Media Queries
*You might have elements on your website that won’t convert well to mobile devices - Identify non-mobile friendly feat.
*Disable Pop-ups 
*Never use Flash
*Navigation bars and tab bars take space on the page, and work well when the number of navigation options is small.
*Hamburger menus accommodate a large number of options, but these options are less discoverable.
*Use shorter sentences and therefore shorter paragraphs.
*Use easy-to-use CTA buttons to the bottom of the page.
*Images -choose right image format, fine detail than highes res - PNG or lossless webp, are u optimizing A
photo or a similar image asset - JPEG or lossy Webp 
*Prefer vector formats: vector images are resolution and scale independent, which makes them a perfect fit for the multi-device and high-resolution world.
*Serve scaled images: resize images and ensure that the "display" size is as close as possible to the "natural" size of the image. 
*<img src="flower-large.jpg" srcset="flower-small.jpg 480w, flower-large.jpg 1080w" sizes="50vw">
*Lazy load images in browser 
*Image CDNs specialize in the transformation, optimization, and delivery of images. 
You can also think of them as APIs for accessing and manipulating the images used on your site.
*Consider using a "fetchpriority" attribute value of "high" on the LCP image element so that the browser can
 begin loading that image as soon as possible.
 *If an image is not immediately discoverable in the initial HTML, consider using a rel=preload hint for your
  LCP candidate image so that the browser can load that image ahead of time.


LOAD 3RD PARTY SCRIPTS - 

*Use async,defer attributes on script tags
*Establish early connections - dns-prefetch, preconnect
*Lazy load embedded videos,media
*Avoid scripts that pollute the global scope
*Use CDNs
*Sub resource integrity 
    Subresource Integrity (SRI) is a security feature that enables browsers to verify that resources they
     fetch (for example, from a CDN) are delivered without unexpected manipulation. 
     It works by allowing you to provide a cryptographic hash that a fetched resource must match.

For embedded media -
*Only HTTPS
*Consider sandbox attr on iframe
*CSP
